import streamlit as st
from components.sql_engine import SQLEngine
from components.nosql_engine import NoSQLEngine

st.set_page_config(page_title="Data Processing System", layout="wide")

st.title("E-Commerce Intelligence System")
st.write("DSCI 551 Fall 2025 - SQL and NoSQL Data Processing")

# Initialize engines in session state
if 'sql_engine' not in st.session_state:
    st.session_state.sql_engine = SQLEngine()
if 'nosql_engine' not in st.session_state:
    st.session_state.nosql_engine = NoSQLEngine()

# Create tabs
tab1, tab2 = st.tabs(["SQL Engine (CSV)", "NoSQL Engine (JSON)"])

# ============= SQL TAB =============
with tab1:
    st.header("SQL Engine - CSV Processing")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("1. Load Data")
        uploaded_file = st.file_uploader("Upload CSV file", type=['csv'], key="sql_upload")
        
        use_chunking = st.checkbox("Enable chunking for large files (>100MB)", value=False)
        if use_chunking:
            chunk_size = st.number_input("Chunk size (rows)", min_value=1000, value=10000, step=1000)
        else:
            chunk_size = None
        
        if st.button("Load CSV", type="primary"):
            if uploaded_file:
                with st.spinner("Loading data..."):
                    success, message = st.session_state.sql_engine.load_data(
                        uploaded_file, chunk_size=chunk_size
                    )
                    if success:
                        st.success(message)
                    else:
                        st.error(message)
            else:
                st.warning("Please upload a CSV file")
    
    with col2:
        st.subheader("2. Data Preview")
        if st.session_state.sql_engine.is_loaded():
            info = st.session_state.sql_engine.get_info()
            st.write(f"**File:** {info['filename']}")
            st.write(f"**Rows:** {info['rows']:,}")
            st.write(f"**Columns:** {info['columns']}")
            if info['chunked']:
                st.write(f"**Mode:** Chunked ({info['chunk_size']:,} rows/batch)")
            else:
                st.write(f"**Mode:** Normal (all in memory)")
            
            st.dataframe(st.session_state.sql_engine.preview(10))
    
    st.divider()
    
    # Query Builder
    if st.session_state.sql_engine.is_loaded():
        st.subheader("3. Build Query")
        
        columns = st.session_state.sql_engine.get_columns()
        
        # Filter
        with st.expander("Filter (WHERE)", expanded=True):
            filter_col = st.selectbox("Column", ["None"] + columns, key="sql_filter_col")
            if filter_col != "None":
                filter_op = st.selectbox("Operator", [">", "<", ">=", "<=", "==", "!="], key="sql_filter_op")
                filter_val = st.text_input("Value", key="sql_filter_val")
                if st.button("Add Filter"):
                    st.session_state.sql_engine.add_filter(filter_col, filter_op, filter_val)
                    st.rerun()
        
        # Select
        with st.expander("Select (PROJECT)"):
            select_cols = st.multiselect("Select columns", columns, key="sql_select")
            if st.button("Add Select"):
                st.session_state.sql_engine.add_select(select_cols)
                st.rerun()
        
        # Group By
        with st.expander("Group By"):
            group_col = st.selectbox("Group by column", columns, key="sql_group")
            agg_func = st.selectbox("Aggregate", ["None", "SUM", "AVG", "COUNT", "MIN", "MAX"])
            agg_col = st.selectbox("Aggregate column", columns, key="sql_agg_col") if agg_func != "None" else None
            if st.button("Add Group By"):
                st.session_state.sql_engine.add_groupby(group_col, agg_func if agg_func != "None" else None, agg_col)
                st.rerun()
        
        # Limit
        with st.expander("Limit"):
            limit_val = st.number_input("Number of rows", min_value=1, value=100, key="sql_limit")
            if st.button("Add Limit"):
                st.session_state.sql_engine.add_limit(limit_val)
                st.rerun()
        
        # Show operations
        operations = st.session_state.sql_engine.get_operations()
        if operations:
            st.write("**Current Query:**")
            for i, op in enumerate(operations):
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.text(f"{i+1}. {op['type']}: {op['description']}")
                with col2:
                    if st.button("Remove", key=f"sql_remove_{i}"):
                        st.session_state.sql_engine.remove_operation(i)
                        st.rerun()
        
        # Execute
        col1, col2 = st.columns(2)
        with col1:
            if st.button("Execute Query", type="primary"):
                with st.spinner("Executing..."):
                    result = st.session_state.sql_engine.execute()
                    if result is not None:
                        st.success(f"Query executed: {len(result) if isinstance(result, list) else 1} results")
                        st.dataframe(result)
                    else:
                        st.error("Query execution failed")
        with col2:
            if st.button("Clear Query"):
                st.session_state.sql_engine.clear_operations()
                st.rerun()

# ============= NOSQL TAB =============
with tab2:
    st.header("NoSQL Engine - JSON Processing")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("1. Load Data")
        uploaded_json = st.file_uploader("Upload JSON file", type=['json'], key="nosql_upload")
        
        if st.button("Load JSON", type="primary"):
            if uploaded_json:
                with st.spinner("Loading data..."):
                    success, message = st.session_state.nosql_engine.load_data(uploaded_json)
                    if success:
                        st.success(message)
                    else:
                        st.error(message)
            else:
                st.warning("Please upload a JSON file")
    
    with col2:
        st.subheader("2. Data Preview")
        if st.session_state.nosql_engine.is_loaded():
            info = st.session_state.nosql_engine.get_info()
            st.write(f"**File:** {info['filename']}")
            st.write(f"**Documents:** {info['count']:,}")
            st.write(f"**Type:** {info['type']}")
            
            preview = st.session_state.nosql_engine.preview(5)
            st.json(preview)
    
    st.divider()
    
    # Query Builder
    if st.session_state.nosql_engine.is_loaded():
        st.subheader("3. Build Query")
        
        fields = st.session_state.nosql_engine.get_fields()
        
        # Filter
        with st.expander("Filter Documents", expanded=True):
            filter_field = st.selectbox("Field", ["None"] + fields, key="nosql_filter_field")
            if filter_field != "None":
                filter_op = st.selectbox("Operator", ["==", "!=", ">", "<", "contains"], key="nosql_filter_op")
                filter_val = st.text_input("Value", key="nosql_filter_val")
                if st.button("Add Filter", key="nosql_add_filter"):
                    st.session_state.nosql_engine.add_filter(filter_field, filter_op, filter_val)
                    st.rerun()
        
        # Project
        with st.expander("Project Fields"):
            project_fields = st.multiselect("Select fields", fields, key="nosql_project")
            if st.button("Add Projection", key="nosql_add_project"):
                st.session_state.nosql_engine.add_projection(project_fields)
                st.rerun()
        
        # Group By
        with st.expander("Group By"):
            group_field = st.selectbox("Group by field", fields, key="nosql_group")
            if st.button("Add Group By", key="nosql_add_group"):
                st.session_state.nosql_engine.add_groupby(group_field)
                st.rerun()
        
        # Limit
        with st.expander("Limit"):
            limit_val = st.number_input("Number of documents", min_value=1, value=100, key="nosql_limit")
            if st.button("Add Limit", key="nosql_add_limit"):
                st.session_state.nosql_engine.add_limit(limit_val)
                st.rerun()
        
        # Show operations
        operations = st.session_state.nosql_engine.get_operations()
        if operations:
            st.write("**Current Query:**")
            for i, op in enumerate(operations):
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.text(f"{i+1}. {op['type']}: {op['description']}")
                with col2:
                    if st.button("Remove", key=f"nosql_remove_{i}"):
                        st.session_state.nosql_engine.remove_operation(i)
                        st.rerun()
        
        # Execute
        col1, col2 = st.columns(2)
        with col1:
            if st.button("Execute Query", type="primary", key="nosql_execute"):
                with st.spinner("Executing..."):
                    result = st.session_state.nosql_engine.execute()
                    if result is not None:
                        st.success(f"Query executed: {len(result)} results")
                        st.json(result)
                    else:
                        st.error("Query execution failed")
        with col2:
            if st.button("Clear Query", key="nosql_clear"):
                st.session_state.nosql_engine.clear_operations()
                st.rerun()

st.divider()
st.caption("DSCI 551 Fall 2025 | Lance Dsilva, Chelroy Limas, Rafayel Mirijanyan")
